{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6c7438e",
   "metadata": {},
   "source": [
    "# Supervised Image Classification\n",
    "\n",
    "\n",
    "- **Special requirements:** A Google account, access to Google Earth Engine.\n",
    "\n",
    "- **Prerequisites:** You should have completed the \"Week 3 - Prac 1\", the \"Week 3 - Prac 2\" notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10fc49d1",
   "metadata": {},
   "source": [
    "\n",
    "## Description\n",
    "Supervised classification is one of the most popular ways to derive thematic maps in remote senisng for applications ranging from generating Land Use/Land Cover maps to change detection. \n",
    "In this session, you will learn how to collect training samples, use machine learning techniques to allocate the whole image to one of the defined categories, perform accuracy assessments, and run some statistics for the resulting classified map. Also, you will learn how to improve the results of classification using post-classification methods.\n",
    "\n",
    "## Aims of the practical session\n",
    "* Load images for a region of interest\n",
    "* Collect training samples\n",
    "* Split samples into training/validation data\n",
    "* Correspond training data with the data\n",
    "* Use classifier\n",
    "* Calculate spectral indices\n",
    "* Improve classification results\n",
    "* Accuracy assessement for training/validation data\n",
    "* Calculating area by class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a01077",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fe2bc6",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "Import GEE packages that are needed for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "metallic-skiing",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f67c57",
   "metadata": {},
   "source": [
    "### Connect to Google Earth Engine (GEE)\n",
    "\n",
    "Connect to the GEE to have access computing tools and GEE datasets.\n",
    "You may be required to input your Google account for authorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4786de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using basemap in geemap\n",
    "Map = geemap.Map(center=[-35.2041, 149.2721], zoom=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d71414",
   "metadata": {},
   "source": [
    "### Adding Region of Interest (ROI)\n",
    "\n",
    "Create ROI that we want to work with and display it on the GEE map.\n",
    "We can also create ROI through manually drawing option in GEE or import a downloaded shapefile from your computer path. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4dc8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw polygon for the ROI and add layer on the GEE map.\n",
    "geometry = ee.Geometry.Polygon([[\n",
    "    [149.08169361455955, -35.32478551096885],\n",
    "    [149.1481265674404, -35.325065623240356],\n",
    "    [149.14829822881737, -35.27911424131675],\n",
    "    [149.08289524419823, -35.27855369756653]\n",
    "]])\n",
    "\n",
    "Map.add_basemap('Esri.WorldImagery')\n",
    "Map.addLayer(geometry, {'alpha': 0.01}, 'Canberra ROI')\n",
    "Map.addLayerControl()\n",
    "Map.centerObject(geometry)\n",
    "Map"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2499c3a1",
   "metadata": {},
   "source": [
    "## Training data\n",
    "\n",
    "Training data (or a training dataset) constitutes the backbone of classification tasks, as it is used to characterise the variability of categories within the study area (in other words, it is used to obtain information instrumental for predicting classes from new data).\n",
    "The quality of the training data has a greater impact on the classification than the algorithm used. Large and accurate training data sets are preferable: increasing the training sample size results in increased classification accuracy ([Maxell et al 2018](https://www.tandfonline.com/doi/full/10.1080/01431161.2018.1433343)). A review of training data methods in the context of Earth Observation is available [here](https://www.mdpi.com/2072-4292/12/6/1034)\n",
    "\n",
    "When creating training labels (i.e., the names of each category/class), be sure to capture the spectral variability of the class, and to use imagery from the time period you want to classify (rather than relying on basemap composites). \n",
    "\n",
    "Another common problem with training data is class imbalance. This can occur when one of your classes is relatively rare and therefore the rare class will comprise a smaller proportion of the training set. When imbalanced data is used, it is common that the final classification will under-predict less abundant classes relative to their true proportion. An ideal training dataset would have approximately the same number of data entries for each of the classes considered.\n",
    "\n",
    "There are many platforms to use for gathering training labels, the best one to use depends on your application.  We will show you how you can collect training data through the web app [geojson.io](https://geojson.io/#map=3.63/-27.46/134.67) - a simple application for drawing geometries on a basemap. \n",
    "\n",
    "Geemap also has some functionality for collecting training samples, though it can be glitchy. To see how its used see the video here: https://www.youtube.com/watch?v=VWh5PxXPZw0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4934df2-1f07-4d1e-b700-050e69661ede",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> \n",
    "\n",
    "## Exercise\n",
    "**Try collecting training samples**. Go to [geojson.io](https://geojson.io/#map=3.63/-27.46/134.67), attempt to collect a few training samples for two to three class labels. Discuss with each other and your demonstrators the challenges you faced.  In this application, we only has access to 'basemaps'. What other kinds of satellite images, band ratios, band indices, or ancillary datasets might help with collecting training samples? Do these differ between the classes? \n",
    "\n",
    "**This exercise is not marked**\n",
    "        \n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53696871",
   "metadata": {},
   "source": [
    "### Loading training samples from file\n",
    "\n",
    "We have prepared a small training data sample for use with this practical. Below we load the file (which is stored on github as a geojson) into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8902d5c-7bda-42fa-a156-fe686c06315e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data from github\n",
    "training_path = 'https://raw.githubusercontent.com/nicolasyounes/engn3903/main/figures/training_data.geojson'\n",
    "training_data = geemap.geojson_to_ee(training_path)\n",
    "\n",
    "#print how many classes there are in the TD\n",
    "df = geemap.ee_to_df(training_data)\n",
    "n_classes = len(df['landcover'].unique())\n",
    "print(f'There are {n_classes} landcover classes in the training dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd764940",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the training samples, add a unique color to each landcover type\n",
    "def setPointProperties(f):\n",
    "  lc = f.get('landcover') # 0 to 3\n",
    "  mapDisplayColors = ee.List(['red', 'green', 'white', 'blue'])\n",
    "\n",
    "  # use the class as index to lookup the corresponding display color\n",
    "  return f.set({'style': {'color': mapDisplayColors.get(lc)}})\n",
    "\n",
    "    \n",
    "# apply the function and view the results on map\n",
    "training_data = training_data.map(setPointProperties)\n",
    "Map.addLayer(training_data.style(**{'styleProperty': 'style'}), {}, 'all training data')\n",
    "Map.centerObject(training_data)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413a4830",
   "metadata": {},
   "source": [
    "### Training data sampling from Sentinel-2 images\n",
    "\n",
    "In the next few code cells we will extract training data from Sentinel-2 images over the pixels specified by the training sample locations loaded in the previous step\n",
    "\n",
    "Sentinel-2 is a wide-swath, high-resolution, multi-spectral imaging mission supporting Copernicus Land Monitoring studies, including the monitoring of vegetation, soil and water cover, as well as observation of inland waterways and coastal areas.\n",
    "\n",
    "We will:\n",
    "* Define a function for cloud masking and rescaling sentinel-2 images\n",
    "* Load Sentinel-2 images for the analysis\n",
    "* Filter a collection by date range\n",
    "* Calculate a temporal median to collapse the time dimension\n",
    "* Clip based on the geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a70a991-cf1d-4f25-b018-e204c79f0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60')\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10\n",
    "    cirrusBitMask = 1 << 11\n",
    "    # Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0) \\\n",
    "        .And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "    \n",
    "    return image.updateMask(mask).divide(10000) #re-scale \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13142ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load sentinel 2\n",
    "S2 = (\n",
    "    ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "    .filterBounds(geometry) #inly images that intersect our ROI\n",
    "    .filterDate('2020-09-01','2020-09-30') ### Note: you can try different dates\n",
    "    .map(maskS2clouds) #map the cloudmasking/rescaling function\n",
    "    .median() #collapse time-dimension using median statistic\n",
    "    .clip(geometry) #'clip' images to the ROI extent\n",
    ")\n",
    "\n",
    "#viualisation prams\n",
    "vis_params = {'min': 0, 'max': 0.4, 'bands': ['B4', 'B3', 'B2']}\n",
    "\n",
    "#add to map\n",
    "Map2 = geemap.Map(center=[-35.30, 149.12], zoom=13)\n",
    "Map2.add_basemap('Esri.WorldImagery')\n",
    "Map2.addLayer(geometry, {'alpha': 0.01}, 'Canberra ROI')\n",
    "Map2.addLayerControl()\n",
    "Map2.addLayer(S2, vis_params, 'Sentinel-2')\n",
    "Map2.addLayer(training_data.style(**{'styleProperty': 'style'}), {}, 'All training data')\n",
    "Map2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c35e34e",
   "metadata": {},
   "source": [
    "### Sample Imagery at training points to create training datasets\n",
    "Now that we have created the points and labels, we need to sample the Sentinel-2 imagery using `image.sampleRegions()`. This command will extract the reflectance values in the designated bands for each of the points you have created. \n",
    "\n",
    "We will then:\n",
    "* Select the bands for training\n",
    "* Sample the input imagery to get a FeatureCollection of training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16ca14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select bands wanted to use in the classification\n",
    "bands = ['B2','B3','B4','B5','B6','B7','B8','B8A','B11','B12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b7fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # correspond training data with S2 data\n",
    "# This property of the table stores the land cover labels.\n",
    "label = 'landcover'\n",
    "\n",
    "#sample the S2 data at the points\n",
    "gcp = S2.select(bands).sampleRegions(\n",
    "    **{'collection': training_data,\n",
    "       'properties': [label],\n",
    "        'scale': 20}\n",
    ")\n",
    "\n",
    "print(f'Size of full training data set: {gcp.size().getInfo()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3968b60e",
   "metadata": {},
   "source": [
    "## Image Classification\n",
    "The <a href=\"https://developers.google.com/earth-engine/guides/classification\">Classifier</a> package contains the supervised classification machine learning algorithms in Earth Engine. In this part we will:\n",
    "* Instantiate a supervised classifier\n",
    "* Set its parameters, if necessary\n",
    "* Train the classifier using the training data\n",
    "* Classify an image using the trained algorithm\n",
    "* Display the classified map\n",
    "\n",
    "> Note: Here we used `Support Vector Machine` model for classification. You can also try different machine learning techniques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9160dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a Support Vector Machine classifier \n",
    "classifier = ee.Classifier.libsvm().train(**{\n",
    "  'features' : gcp,\n",
    "  'classProperty' : 'landcover',\n",
    "  'inputProperties' : bands\n",
    "})\n",
    "\n",
    "#classify the pixels in the image\n",
    "classified = S2.select(bands).classify(classifier)\n",
    "\n",
    "# quickly show the result using random colours\n",
    "Map2.addLayer(classified.randomVisualizer(), {}, 'Classified')\n",
    "Map2.addLayer(training_data.style(**{'styleProperty': 'style'}), {}, 'All training data')\n",
    "Map2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4fb7a52",
   "metadata": {},
   "source": [
    "## Accuracy assessment\n",
    "To assess the accuracy of a classifier use a Confusion Matrix (<a href=\"http://www.sciencedirect.com/science/article/pii/S0034425797000837\">Stehman 1997</a>) and we will also calculate overall accuracy (OA).\n",
    "\n",
    "A Confusion matrix is an N x N matrix used for evaluating the performance of a classification model, where N is the number of target classes. The matrix compares the actual target values with those predicted by a machine learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c627b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "train_accuracy = classifier.confusionMatrix()\n",
    "train_accuracy.getInfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fc4cf1-d2b6-4b30-9157-5af3d764c998",
   "metadata": {},
   "source": [
    "We can convert the `train_accuracy.getInfo()` results into a nicer looking (more readable) Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3301525-7f26-45b8-98d9-5bc3a6d95961",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_matrix = pd.DataFrame(train_accuracy.getInfo())\n",
    "df_matrix.columns.name = 'PREDICTION'\n",
    "df_matrix.index.name = 'ACTUAL'\n",
    "df_matrix.loc['TOTAL',:]= df_matrix.sum(axis=0)\n",
    "#Total sum per row: \n",
    "df_matrix.loc[:,'TOTAL'] = df_matrix.sum(axis=1)\n",
    "df_matrix=df_matrix.rename(columns={0:'highveg', 1:'lowveg', 2:'urban', 3:'water'},\n",
    "             index={0:'highveg', 1:'lowveg', 2:'urban', 3:'water'})\n",
    "df_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7edbc1-5e7b-4e1d-8cd7-d530522422a7",
   "metadata": {},
   "source": [
    "Now, let's print the overall accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cf12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall accuracy\n",
    "print(f'Overall classification accuracy of the model is: {train_accuracy.accuracy().getInfo()*100:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dbcfd0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> \n",
    "\n",
    "## Exercise 1 - Supervised classification of Sentinel-2: explain the results of the confusion matrix  \n",
    "1. Why might we use a confusion matrix to explain the results of a classification task rather than simply using the overall accuracy score?\n",
    "2. What was the omission error for each class? What was the commission error for each class? These errors are sometimes also called Producer's Accuracy (omission error) and User's Accuray (commission error), which is the inverse of the error (i.e. 100% - accuracy = error).\n",
    "3. What are the classes that experienced more or less confusion? Why might this be?\n",
    "4. What could you do to improve the classification results?\n",
    "5. Do you think its correct to train and test a machine learning model on the same data?\n",
    "\n",
    "Some resources to help you better understand confusion matrices:\n",
    "\n",
    "* https://link.springer.com/chapter/10.1007/978-3-031-26588-4_7\n",
    "* https://www.youtube.com/watch?v=6XHyYh45PxA\n",
    "* https://medium.com/analytics-vidhya/what-is-a-confusion-matrix-d1c0f8feda5\n",
    "  \n",
    "<div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd3bd70",
   "metadata": {},
   "source": [
    "## Split the samples into training/test sets\n",
    "The goal here is to split up the training sample into training data (70% of the total sample) and validation data (30% of the total data) (with randomization). The training set is used to train the model and test set is used to validate it. This is best practice in the machine learning community."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f2605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This property of the table stores the land cover labels.\n",
    "label = 'landcover'\n",
    "\n",
    "# Add a random column and split the GCPs into training and validation set\n",
    "gcp = training_data.randomColumn()\n",
    "\n",
    "# This being a simpler classification, we take 30% points\n",
    "# for validation.\n",
    "trainingGcp = gcp.filter('random <= 0.7')\n",
    "validationGcp = gcp.filter('random > 0.7')\n",
    "\n",
    "Map2.addLayer(validationGcp.style(**{'styleProperty': 'style'}), {}, 'Valildation points')\n",
    "\n",
    "# # Overlay the point on the image to get training data.\n",
    "composite = S2.select(bands)\n",
    "training = composite.sampleRegions(\n",
    "    **{\n",
    "  'collection': trainingGcp,\n",
    "  'properties': [label],\n",
    "  'scale': 20}\n",
    ")\n",
    "\n",
    "print('Training data size: ', training.size().getInfo())\n",
    "print('Validation data size: ',validationGcp.size().getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6ce004-06ce-443c-b34c-5a8087c9c3be",
   "metadata": {},
   "source": [
    "Now we will reclassify the image using only the 70 % training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "309c72ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # classifier\n",
    "classifier1 = ee.Classifier.libsvm().train(**{\n",
    "  'features' : training,\n",
    "  'classProperty' : 'landcover',\n",
    "  'inputProperties' : bands\n",
    "})\n",
    "\n",
    "classified = composite.classify(classifier1)\n",
    "\n",
    "# # Display the clusters with random colors.\n",
    "Map2.addLayer(classified.randomVisualizer(), {}, 'Classified - training subset')\n",
    "Map2.addLayer(trainingGcp.style(**{'styleProperty': 'style'}), {}, 'Training subset')\n",
    "Map2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a40a9c",
   "metadata": {},
   "source": [
    "### Accuracy assessment\n",
    "\n",
    "We can now conduct a similar accuracy assessment to the one we previously did, but this time using only the validation samples to test the accuracy (these validation samples were not used in the training of the classifier) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a861054f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Accuracy Assessment\n",
    "test = classified.sampleRegions(\n",
    "    **{\n",
    "  'collection': validationGcp,\n",
    "  'properties': [label],\n",
    "  'scale': 10}\n",
    ")\n",
    "print(test.size().getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f20fbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # confusion matrix\n",
    "test_accuracy = test.errorMatrix('landcover', 'classification')\n",
    "test_accuracy.getInfo()\n",
    "\n",
    "df_matrix = pd.DataFrame(test_accuracy.getInfo())\n",
    "df_matrix.columns.name = 'PREDICTION'\n",
    "df_matrix.index.name = 'ACTUAL'\n",
    "df_matrix.loc['TOTAL',:]= df_matrix.sum(axis=0)\n",
    "#Total sum per row: \n",
    "df_matrix.loc[:,'TOTAL'] = df_matrix.sum(axis=1)\n",
    "df_matrix=df_matrix.rename(columns={0:'highveg', 1:'lowveg', 2:'urban', 3:'water'},\n",
    "             index={0:'highveg', 1:'lowveg', 2:'urban', 3:'water'})\n",
    "df_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead5a21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall accuracy\n",
    "print(f'Overall classification accuracy of the model is: {test_accuracy.accuracy().getInfo()*100:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec0872",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> \n",
    "\n",
    "## Exercise 2\n",
    "\n",
    "Compare the accuracy from your intial classification results with those after you conducted a train-test split:\n",
    "1. Did the accuracy change? If so, why?\n",
    "2. Explain briefly why it is important in machine learning classification to implement train-test splits? There is a lot of material on the internet that might help you with this answer.\n",
    "\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c851940",
   "metadata": {},
   "source": [
    "### Download confusion matrix\n",
    "Use the following code to download the calculated confusion matrix and save it as CSV file **at the location you can set below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9eacb2-c1f1-41b6-a9fa-e0be21f11269",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change this to your folder!scratch/du53/engn3903/week4\n",
    "export_path = '/scratch/du53/engn3903/week4/'\n",
    "\n",
    "df_matrix.to_csv(export_path+'test_accuracy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943ebeeb",
   "metadata": {},
   "source": [
    "### Export the classified result\n",
    "\n",
    "Export the result as a geotiff to the same location as the confusion matrix csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ab193f",
   "metadata": {},
   "outputs": [],
   "source": [
    "geemap.ee_export_image(classified, filename=export_path+'landcover.tif', scale=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03d778da",
   "metadata": {},
   "source": [
    "## Extracting information from the classified map\n",
    "This code shows how to calculate the area covered by each class in a classified image and display it in a chart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af57980c",
   "metadata": {},
   "outputs": [],
   "source": [
    "######/ Calculating Area by Class\n",
    "\n",
    "# Create a 2 band image with the area image and the classified image\n",
    "# Divide the area image by 1e6 so area results are in Sq Km\n",
    "areaImage = ee.Image.pixelArea().divide(1e6).addBands(classified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae69394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Area by Class\n",
    "# Using a Grouped Reducer, in this case summing the pixel areas\n",
    "# to get total area\n",
    "areas = areaImage.reduceRegion(**{\n",
    "      'reducer': ee.Reducer.sum().group(**{\n",
    "      'groupField': 1,\n",
    "      'groupName': 'classification',\n",
    "    }),\n",
    "    'geometry': geometry,\n",
    "    'scale': 20,\n",
    "    'maxPixels': 1e9\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50c4c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "classAreas = ee.List(areas.get('groups'))\n",
    "print(classAreas.getInfo())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3120f26",
   "metadata": {},
   "source": [
    "### Create a chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9420b5c5-b9d4-4256-8a7e-2f4952a15da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_areas = pd.DataFrame(classAreas.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2948c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_areas['sum'].plot.bar(figsize=(5,5))\n",
    "classLabels = ['highveg', 'lowveg', 'urban', 'water']\n",
    "plt.xticks([0,1,2,3], classLabels)\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Area Km$^2$')\n",
    "plt.title('Area by class', fontsize=16);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eaeb1ff",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> \n",
    "\n",
    "## Exercise 3 - Lets put all what you have learnt together. \n",
    "\n",
    "Run a classification to try to improve the results. For example, you may want to use only the bands where there is less overlap between the different classes, or maybe you should add some band indices? What about the model?\n",
    "\n",
    "Then explain what you did and answer the following questions:\n",
    "1. Compare the confusion matrices. Has the accuracy of the model changed? why? \n",
    "2. Recalculate area by class, plot the result, and explain why there are differences (if any).\n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613f51a0",
   "metadata": {},
   "source": [
    "## References\n",
    "This is where the references go. For example:\n",
    "\n",
    "* Wu, Q., (2020). geemap: A Python package for interactive mapping with Google Earth Engine. The Journal of Open Source Software, 5(51), 2305. https://doi.org/10.21105/joss.02305\n",
    "\n",
    "* \"Earth Observation: Data, Processing and Applications\" book. Available through Wattle, or http://www.crcsi.com.au/earth-observation-series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa334255",
   "metadata": {},
   "source": [
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the ENGN3903 Wattle site. \n",
    "\n",
    "**Last modified:** August 2024"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
