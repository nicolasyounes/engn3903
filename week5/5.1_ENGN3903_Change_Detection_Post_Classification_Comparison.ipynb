{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad4cd69c",
   "metadata": {},
   "source": [
    "## Description\n",
    "Many earth observation datasets are available at regular intervals over long periods of time. This enables us to detect changes on the Earth’s surface. In this session, you will learn how to apply change detection technique in remote sensing.\n",
    "\n",
    "## Aims of the practical session\n",
    "* Create ROI and load it\n",
    "* Collect images and training samples\n",
    "* Apply classification algorithms to classify images before and after an event\n",
    "* Comparing two classified images to see the changes during the time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e23b83",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e1de05",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "Import GEE packages that are needed for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a31431e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e0220",
   "metadata": {},
   "source": [
    "### Connect to Google Earth Engine (GEE)\n",
    "\n",
    "Connect to the GEE to have access computing tools and GEE datasets.\n",
    "You may be required to input your Google account for authorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df8c7dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3325775dcdf44c9abd256a0553b587f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[20, 0], controls=(WidgetControl(options=['position', 'transparent_bg'], widget=HBox(children=(Togg…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import geemap\n",
    "Map = geemap.Map()\n",
    "# Map.add_basemap('HYBRID')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0e75a",
   "metadata": {},
   "source": [
    "### Adding Region of Interest (ROI)\n",
    "\n",
    "Create ROI that we want to work on it and then add and display it on the GEE map.\n",
    "Import the downloaded shapefile for Canberra central from your computer path as ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d87f35e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abolfazl\\Anaconda3\\envs\\gee\\lib\\site-packages\\geopandas\\io\\file.py:299: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "# # # load shapefile (ROI)\n",
    "shp_path = 'D:/GEE Tutorials/NOV21_ACT_LOC_POLYGON_shp/Canberra_central.shp'\n",
    "geometry = geemap.shp_to_ee(shp_path)\n",
    "Map.addLayer(geometry, {}, 'Canberra central SHP')\n",
    "Map.centerObject(geometry);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19d464",
   "metadata": {},
   "source": [
    "### Training data\n",
    "Training data (or a training dataset) is the initial data used to train machine learning models. Import your pre-selected training dataset from your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3912f232",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abolfazl\\Anaconda3\\envs\\gee\\lib\\site-packages\\geopandas\\io\\file.py:299: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  pd.Int64Index,\n"
     ]
    }
   ],
   "source": [
    "#### load training data\n",
    "trainingS_path = 'C:/Users/Abolfazl/Desktop/code/Google Earth Engine/training_data.shp'\n",
    "training_data = geemap.shp_to_ee(trainingS_path)\n",
    "Map.addLayer(training_data, {}, 'training_data')\n",
    "Map.centerObject(training_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9971a18",
   "metadata": {},
   "source": [
    "### Before Image collection \n",
    "An ImageCollection is a stack or sequence of images. An ImageCollection can be loaded by pasting an Earth Engine asset ID into the ImageCollection constructor. You can find ImageCollection IDs in the <a href=\"https://developers.google.com/earth-engine/datasets\">data catalog</a>. \n",
    "\n",
    "We will:\n",
    "* Load before Landsat-8 images for the anlysis\n",
    "* Filter a collection by date range\n",
    "* Make a cloud-free composite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1ba70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Make a cloud-free Landsat 8 TOA composite (Before imagery).\n",
    "landsatCollectionB = ee.ImageCollection('LANDSAT/LC08/C01/T1') \\\n",
    "    .filterDate('2015-03-01', '2015-03-31')\\\n",
    "    .filterBounds(geometry)\n",
    "    #.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
    "    #.sort('CLOUD_COVER')\n",
    "    #.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bc55b29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(landsatCollectionB.size().getInfo());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cabec05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # Use these bands for prediction.\n",
    "bands = ['B2', 'B3', 'B4', 'B5', 'B6', 'B7', 'B10', 'B11']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57884666",
   "metadata": {},
   "source": [
    "### Make a cloud-free composite\n",
    "Computes a Landsat TOA composite from a collection of raw Landsat scenes. It applies standard TOA calibration and then assigns a cloud score to each pixel using the SimpleLandsatCloudScore algorithm. It selects the lowest possible range of cloud scores at each point and then computes per-band percentile values from the accepted pixels. This algorithm also uses the LandsatPathRowLimit algorithm to select only the least-cloudy scenes in regions where more than maxDepth input scenes are available. More information can be found <a href=\"https://developers.google.com/earth-engine/apidocs/ee-algorithms-landsat-simplecomposite\">simpleComposite</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ff9293a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a cloud-free composite.\n",
    "compositeB = ee.Algorithms.Landsat.simpleComposite(**{\n",
    "  'collection': landsatCollectionB,\n",
    "  'asFloat': True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b8de1",
   "metadata": {},
   "source": [
    "### Visualize the composite\n",
    "* Clip based on the geometry\n",
    "* Display it on Geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52b51c58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3325775dcdf44c9abd256a0553b587f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=20298425.0, center=[-35.17380831799957, 149.06250000000003], controls=(WidgetControl(options=['posi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the Composite\n",
    "compositeB = compositeB.clip(geometry).select(bands)\n",
    "Map.addLayer(compositeB, {'bands': ['B4',  'B3',  'B2'], 'max': 0.5, 'gamma': 2}, 'L8 Image Before', True)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574462a",
   "metadata": {},
   "source": [
    "### Overlay the point on the image to get training data\n",
    "Now that we have created the points and labels, we need to sample the imagery using image.sampleRegions(). This command will extract the reflectance in the designated bands for each of the points you have created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d4bf21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the point on the image to get training data.\n",
    "training = compositeB.sampleRegions(**{\n",
    "  'collection': training_data,\n",
    "  'properties': ['landcover'],\n",
    "  'scale': 30\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72535d",
   "metadata": {},
   "source": [
    "### Classifcation method\n",
    "The <a href=\"https://developers.google.com/earth-engine/guides/classification\">Classifier</a> package in handles supervised classification by ML algorithms running in Earth Engine. Thus, in this part we will:\n",
    "* Instantiate a supervised classifier\n",
    "* Set its parameters if necessary\n",
    "* Train the classifier using the training data\n",
    "* Classify an image or feature collection\n",
    "* Display the classified map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "def4cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier.\n",
    "classifier = ee.Classifier.smileRandomForest(50).train(**{\n",
    "  'features': training,\n",
    "  'classProperty': 'landcover',\n",
    "  'inputProperties': compositeB.bandNames()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3b12b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3325775dcdf44c9abd256a0553b587f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=20298425.0, center=[-35.17380831799957, 149.06250000000003], controls=(WidgetControl(options=['posi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Classify the image.\n",
    "beforeClassified = compositeB.classify(classifier)\n",
    "Map.addLayer(beforeClassified,{'min': 0, 'max': 3, 'palette': ['blue', 'green', 'yellow', 'red']}, 'before_classified')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb52e56",
   "metadata": {},
   "source": [
    "### After Image collection \n",
    "We will:\n",
    "* Load after Landsat-8 images for the anlysis\n",
    "* Filter a collection by date range\n",
    "* Make a cloud-free composite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bad4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # After Images.\n",
    "landsatCollectionA = ee.ImageCollection('LANDSAT/LC08/C01/T1') \\\n",
    "    .filterDate('2021-03-01', '2021-03-31') \\\n",
    "    .filterBounds(geometry)\n",
    "    #.filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 10))\n",
    "    #.sort('CLOUD_COVER')\n",
    "    #.first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce779a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(landsatCollectionB.size().getInfo());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f77634",
   "metadata": {},
   "source": [
    "### Make a cloud-free composite\n",
    "Use SimpleLandsatCloudScore algorithm to computes a Landsat TOA composite from a collection of raw Landsat scenes. It applies standard TOA calibration and then assigns a cloud score to each pixel. More information can be found <a href=\"https://developers.google.com/earth-engine/apidocs/ee-algorithms-landsat-simplecomposite\">simpleComposite</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3936852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a cloud-free composite.\n",
    "compositeA = ee.Algorithms.Landsat.simpleComposite(**{\n",
    "  'collection': landsatCollectionA,\n",
    "  'asFloat': True\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a5f2bb",
   "metadata": {},
   "source": [
    "### Visualize the composite\n",
    "* Clip based on the geometry\n",
    "* Display it on Geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "664c68ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3325775dcdf44c9abd256a0553b587f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=20298425.0, center=[-35.17380831799957, 149.06250000000003], controls=(WidgetControl(options=['posi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize the Composite\n",
    "compositeA = compositeA.clip(geometry).select(bands)\n",
    "Map.addLayer(compositeA, {'bands': ['B4',  'B3',  'B2'], 'max': 0.5, 'gamma': 2}, 'L8 Image After', True)\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9762e5",
   "metadata": {},
   "source": [
    "### Classify the image\n",
    "* Apply the same supervised classifier on after image\n",
    "* Classify an image or feature collection\n",
    "* Display the classified map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9dfd8ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3325775dcdf44c9abd256a0553b587f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=20298425.0, center=[-35.17380831799957, 149.06250000000003], controls=(WidgetControl(options=['posi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Classify the image.\n",
    "afterClassified= compositeA.classify(classifier)\n",
    "Map.addLayer(afterClassified,{'min': 0, 'max': 3, 'palette': ['blue', 'green', 'yellow', 'red']}, 'after_classified')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f34c5",
   "metadata": {},
   "source": [
    "### <a name=\"ex3\"></a> Challenge\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "- Try to calculate the accuracy of the method for both pre and post-classifcation results to see if the performance of the model is satisfactory. \n",
    "    \n",
    "    \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b480925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reclassify from 0-3 to 1-4\n",
    "beforeClasses = beforeClassified.remap([0, 1, 2, 3], [1, 2, 3, 4])\n",
    "afterClasses = afterClassified.remap([0, 1, 2, 3], [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a77f6f",
   "metadata": {},
   "source": [
    "### Post-classification comparison\n",
    "We dealing with multi-class images, a useful metric for change detection is to know how many pixels from class X changed to class Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1deed67e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3325775dcdf44c9abd256a0553b587f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=20298425.0, center=[-35.17380831799957, 149.06250000000003], controls=(WidgetControl(options=['posi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show all changed areas\n",
    "changed = afterClasses.subtract(beforeClasses).neq(0)\n",
    "Map.addLayer(changed, {'min':0, 'max':1, 'palette': ['white', 'red']}, 'Change')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74afe04",
   "metadata": {},
   "source": [
    "<span style='background:yellow'> <span style=\"font-size:16.0pt\"> Exercise  </span>\n",
    "\n",
    "### Exercise 1 - Calculate area by each transition class \n",
    "Try to add the before image with the after image to represent each unique transition of pixel values\n",
    "\n",
    "#### Then try to check the following exercises:\n",
    "* Calculate the area of each class transition?\n",
    "* You can use a grouped reducer\n",
    "* Show all areas where each class became other class and display the result\n",
    "* Post-process the result to generate a clean output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bdc079",
   "metadata": {},
   "source": [
    "## References\n",
    "This is where the references go. For exmaple:\n",
    "\n",
    "* Wu, Q., (2020). geemap: A Python package for interactive mapping with Google Earth Engine. The Journal of Open Source Software, 5(51), 2305. https://doi.org/10.21105/joss.02305\n",
    "* \"Earth Observation: Data, Processing and Applications\" book. Available through Wattle, or http://www.crcsi.com.au/earth-observation-series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c86f987",
   "metadata": {},
   "source": [
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook was initially created by the team at [Digital Earth Australia](https://github.com/GeoscienceAustralia/dea-notebooks), and has been modified by Abolfazl Abdollahi. The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the ENGN3903 Wattle site.\n",
    "\n",
    "**Last modified:** June 2022"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1e723e",
   "metadata": {},
   "source": [
    "### Exercise answers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4a9724",
   "metadata": {},
   "source": [
    "<a name=\"ex1answer\">Answer to Exercise 1</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c970f17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # We multiply the before image with 100 and add the after image\n",
    "# # The resulting pixel values will be unique and will represent each unique transition\n",
    "# merged = beforeClasses.multiply(100).add(afterClasses).rename('transitions')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "604ec298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Calculate Area by each Transition Class\n",
    "# # using a Grouped Reducer\n",
    "# # Divide by 1e6 to get the area in sq.km.\n",
    "# areaImage = ee.Image.pixelArea().divide(1e6).addBands(merged)\n",
    "\n",
    "# areas = areaImage.reduceRegion(**{\n",
    "#       'reducer': ee.Reducer.sum().group(**{\n",
    "#       'groupField': 1,\n",
    "#       'groupName': 'transitions',\n",
    "#     }),\n",
    "#     'geometry': geometry,\n",
    "#     'scale': 30,\n",
    "#     'maxPixels': 1e9\n",
    "#     })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00d67a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'101': 28, '102': 0, '103': 1, '104': 0, '201': 9, '202': 6, '203': 2, '204': 0, '301': 15, '302': 2, '303': 19, '304': 0, '401': 0, '402': 0, '403': 0, '404': 6}\n"
     ]
    }
   ],
   "source": [
    "# # Post-process the result to generate a clean output\n",
    "# classAreas = ee.List(areas.get('groups'))\n",
    "\n",
    "# def cleanOutput(item):\n",
    "#       areaDict = ee.Dictionary(item)\n",
    "#       classNumber = ee.Number(areaDict.get('transitions')).format()\n",
    "#       area = ee.Number(areaDict.get('sum')).round()\n",
    "#       return ee.List([classNumber, area])\n",
    "\n",
    "# classAreaLists = classAreas.map(cleanOutput)\n",
    "\n",
    "# classTransitionsAreaDict = ee.Dictionary(classAreaLists.flatten())\n",
    "# print(classTransitionsAreaDict.getInfo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6bc10156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Transition  Area\n",
      "0         101    28\n",
      "1         102     0\n",
      "2         103     1\n",
      "3         104     0\n",
      "4         201     9\n",
      "5         202     6\n",
      "6         203     2\n",
      "7         204     0\n",
      "8         301    15\n",
      "9         302     2\n",
      "10        303    19\n",
      "11        304     0\n",
      "12        401     0\n",
      "13        402     0\n",
      "14        403     0\n",
      "15        404     6\n",
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "# ## Plot the results\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# import pandas as pd\n",
    "\n",
    "# my_dict = {'101': 28, '102': 0, '103': 1, '104': 0, '201': 9, '202': 6, '203': 2, '204': 0, '301': 15, '302': 2, '303': 19,\n",
    "#            '304': 0, '401': 0, '402': 0, '403': 0, '404': 6}\n",
    "# df = pd.DataFrame(list(my_dict.items()),columns = ['Transition','Area'])\n",
    "\n",
    "# print (df)\n",
    "# print (type(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cfa19bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # a scatter plot comparing num_children and num_pets\n",
    "# df.plot(kind='bar',x='Transition',y='Area',color='red')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5a6e8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
