{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6979f92a",
   "metadata": {},
   "source": [
    "# Change Detection (Post-classification Comparison)\n",
    "\n",
    "\n",
    "- **Special requirements:** A Google account, access to Google Earth Engine.\n",
    "\n",
    "- **Prerequisites:** You should have completed the \"Week 4 - Prac 1\" notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4cd69c",
   "metadata": {},
   "source": [
    "## Description\n",
    "Many earth observation datasets are available at regular intervals over long periods of time. This enables us to detect changes on the Earthâ€™s surface. In this session, you will learn how to apply change detection technique in remote sensing.\n",
    "\n",
    "## Aims of the practical session\n",
    "* Create ROI and load it\n",
    "* Collect images and training samples\n",
    "* Apply classification algorithms to classify images before and after an event\n",
    "* Comparing two classified images to see the changes during the time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e23b83",
   "metadata": {},
   "source": [
    "## Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e1de05",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "Import GEE packages that are needed for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31431e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ee\n",
    "import geemap\n",
    "# ee.Authenticate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9e0220",
   "metadata": {},
   "source": [
    "### Connect to Google Earth Engine (GEE)\n",
    "\n",
    "Connect to the GEE to have access computing tools and GEE datasets.\n",
    "You may be required to input your Google account for authorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8c7dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geemap\n",
    "Map = geemap.Map()\n",
    "# Map.add_basemap('HYBRID')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0e75a",
   "metadata": {},
   "source": [
    "### Adding Region of Interest (ROI)\n",
    "\n",
    "Create ROI that we want to work on it and then add and display it on the GEE map.\n",
    "Import the downloaded shapefile for Canberra central from your computer path as ROI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87f35e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # load shapefile (ROI)\n",
    "shp_path = 'C:/UserData/abdollaa/OneDrive - Australian National University/Tutorials/GEE/NOV21_ACT_LOC_POLYGON_shp/Canberra_central.shp'\n",
    "geometry = geemap.shp_to_ee(shp_path)\n",
    "Map.addLayer(geometry, {}, 'Canberra central SHP')\n",
    "Map.centerObject(geometry);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e19d464",
   "metadata": {},
   "source": [
    "### Training data\n",
    "Training data (or a training dataset) is the initial data used to train machine learning models. Import your pre-selected training dataset from your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3912f232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load training data\n",
    "training_path = \"https://raw.githubusercontent.com/nicolasyounes/engn3903/main/figures/training_data.geojson\"\n",
    "training_data = geemap.geojson_to_ee(training_path)\n",
    "\n",
    "#print how many classes there are in the TD\n",
    "df = geemap.ee_to_geopandas(training_data)\n",
    "n_classes = len(df['landcover'].unique())\n",
    "print(f'There are {n_classes} landcover classes in the training dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9971a18",
   "metadata": {},
   "source": [
    "### Before Image collection \n",
    "\n",
    "In the next few code cells we will extract training data from Sentinel-2 images over the pixels specified by the training sample locations loaded from the URL page.\n",
    "\n",
    "Sentinel-2 is a wide-swath, high-resolution, multi-spectral imaging mission supporting Copernicus Land Monitoring studies, including the monitoring of vegetation, soil and water cover, as well as observation of inland waterways and coastal areas.\n",
    "\n",
    "We will:\n",
    "* Define a function for cloud masing and resabling sentinel-2 images\n",
    "* Load Sentinel-2 images for the analysis\n",
    "* Filter a collection by date range\n",
    "* Calculate a temporal median to collapse the time dimension\n",
    "* Clip based on the geometry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ba70a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskS2clouds(image):\n",
    "    qa = image.select('QA60')\n",
    "    # Bits 10 and 11 are clouds and cirrus, respectively.\n",
    "    cloudBitMask = 1 << 10\n",
    "    cirrusBitMask = 1 << 11\n",
    "    # Both flags should be set to zero, indicating clear conditions.\n",
    "    mask = qa.bitwiseAnd(cloudBitMask).eq(0) \\\n",
    "        .And(qa.bitwiseAnd(cirrusBitMask).eq(0))\n",
    "    \n",
    "    return image.updateMask(mask).divide(10000) #re-scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc55b29f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## collect before event images \n",
    "S2_before = (\n",
    "    ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "    .filterBounds(geometry)\n",
    "    .filterDate('2019-10-01', '2019-10-31') ### Note: you can try different dates\n",
    "    .map(maskS2clouds) #map the cloudmasking/rescaling function\n",
    "    .median()\n",
    "    .clip(geometry)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabec05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select bands wanted to use in the classification\n",
    "bands = ['B2','B3','B4','B5','B6','B7','B8','B8A','B11','B12']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b8de1",
   "metadata": {},
   "source": [
    "### Visualize the composite\n",
    "* Clip based on the geometry\n",
    "* Display it on Geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b51c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_params = {'min': 0, 'max': 0.4, 'bands': ['B4', 'B3', 'B2']}\n",
    "\n",
    "#Map.centerObject(point, 8)\n",
    "Map.addLayer(S2_before, vis_params, \"Sentinel2_before\")\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0574462a",
   "metadata": {},
   "source": [
    "### Overlay the point on the image to get training data\n",
    "Now that we have created the points and labels, we need to sample the imagery using image.sampleRegions(). This command will extract the reflectance in the designated bands for each of the points you have created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bf21dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overlay the point on the image to get training data.\n",
    "training = S2_before.sampleRegions(**{\n",
    "  'collection': training_data,\n",
    "  'properties': ['landcover'],\n",
    "  'scale': 20\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d72535d",
   "metadata": {},
   "source": [
    "### Classifcation method\n",
    "The <a href=\"https://developers.google.com/earth-engine/guides/classification\">Classifier</a> package in handles supervised classification by ML algorithms running in Earth Engine. Thus, in this part we will:\n",
    "* Instantiate a supervised classifier\n",
    "* Set its parameters if necessary\n",
    "* Train the classifier using the training data\n",
    "* Classify an image or feature collection\n",
    "* Display the classified map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4cce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a classifier.\n",
    "classifier = ee.Classifier.smileRandomForest(50).train(**{\n",
    "  'features': training,\n",
    "  'classProperty': 'landcover',\n",
    "  'inputProperties': bands\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b12b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Classify the image.\n",
    "beforeClassified = S2_before.classify(classifier)\n",
    "Map.addLayer(beforeClassified,{'min': 0, 'max': 3, 'palette': ['blue', 'green', 'yellow', 'red']}, 'before_classified')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb52e56",
   "metadata": {},
   "source": [
    "### After Image collection \n",
    "We will:\n",
    "* Load after Landsat-8 images for the anlysis\n",
    "* Filter a collection by date range\n",
    "* Make a cloud-free composite "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad4cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # After Images.\n",
    "S2_after = (\n",
    "    ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED')\n",
    "    .filterBounds(geometry)\n",
    "    .filterDate('2021-10-01', '2021-10-31') ### Note: you can try different dates\n",
    "    .map(maskS2clouds) #map the cloudmasking/rescaling function\n",
    "    .median()\n",
    "    .clip(geometry)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce779a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # select bands wanted to use in the classification\n",
    "bands = ['B2','B3','B4','B5','B6','B7','B8','B8A','B11','B12']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3a5f2bb",
   "metadata": {},
   "source": [
    "### Visualize the composite\n",
    "* Clip based on the geometry\n",
    "* Display it on Geemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664c68ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the Composite\n",
    "vis_params = {'min': 0, 'max': 0.4, 'bands': ['B4', 'B3', 'B2']}\n",
    "\n",
    "# Map.centerObject(point, 8)\n",
    "Map.addLayer(S2_after, vis_params, \"Sentinel2_after\")\n",
    "Map.addLayerControl()\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9762e5",
   "metadata": {},
   "source": [
    "### Classify the image\n",
    "* Apply the same supervised classifier on after image\n",
    "* Classify an image or feature collection\n",
    "* Display the classified map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfd8ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classify the image.\n",
    "afterClassified= S2_after.classify(classifier)\n",
    "Map.addLayer(afterClassified,{'min': 0, 'max': 3, 'palette': ['blue', 'green', 'yellow', 'red']}, 'after_classified')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "471f34c5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> \n",
    "\n",
    "### Exercise 1: Accuracy Assessment\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "- Try to calculate the accuracy of the method for both pre and post-classifcation results to see if the performance of the model is satisfactory and compare the results. \n",
    "    \n",
    "    \n",
    "</div> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b480925f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reclassify from 0-3 to 1-4\n",
    "beforeClasses = beforeClassified.remap([0, 1, 2, 3], [1, 2, 3, 4])\n",
    "afterClasses = afterClassified.remap([0, 1, 2, 3], [1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a77f6f",
   "metadata": {},
   "source": [
    "### Post-classification comparison\n",
    "We dealing with multi-class images, a useful metric for change detection is to know how many pixels from class X changed to class Y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1deed67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all changed areas\n",
    "changed = afterClasses.subtract(beforeClasses).neq(0)\n",
    "Map.addLayer(changed, {'min':0, 'max':1, 'palette': ['white', 'red']}, 'Change')\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74afe04",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\"> \n",
    "    \n",
    "### Exercise 2 - Calculate area by each transition class \n",
    "Try to calculate area covered by each class in a classified images (before and after) and display it in a chart.\n",
    "\n",
    "#### Then try to check the following exercises after applying change detection:\n",
    "* Calculate the area of each class in each classifcation.\n",
    "* Discuss if the changes involve a decrease in a class, lead to an increase, or keep unchanged. \n",
    "<div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bdc079",
   "metadata": {},
   "source": [
    "## References\n",
    "This is where the references go. For exmaple:\n",
    "\n",
    "* Wu, Q., (2020). geemap: A Python package for interactive mapping with Google Earth Engine. The Journal of Open Source Software, 5(51), 2305. https://doi.org/10.21105/joss.02305\n",
    "* \"Earth Observation: Data, Processing and Applications\" book. Available through Wattle, or http://www.crcsi.com.au/earth-observation-series."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c86f987",
   "metadata": {},
   "source": [
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook was initially created by the team at [Digital Earth Australia](https://github.com/GeoscienceAustralia/dea-notebooks), and has been modified by Abolfazl Abdollahi. The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the ENGN3903 Wattle site.\n",
    "\n",
    "**Last modified:** August 2022"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
