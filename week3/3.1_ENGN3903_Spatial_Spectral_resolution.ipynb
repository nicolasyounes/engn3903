{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial and spectral resolutions.\n",
    "\n",
    "* **Special requirements:** A Google account, access to Google Earth Engine.\n",
    "* **Prerequisites:** You should have completed the `2.1_ENGN3903_Satellite images and bands`, the `2.2 ENGN3903_Images, collections, and filters` notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "> Note: Refer to Lecture 2 of week 2 for the relevant content for this lab\n",
    "\n",
    "Resolution is the ability to discriminate information in an image. The discrimination of information refers not only to the spatial detail (spatial resolution) but also to the number of spectral wavebands, their bandwidths, and spectral cover (spectral resolution), the temporal frequency of observations (temporal resolution) and the signal to noise ratio or its ability to distinguish variations in the energy detected (radiomatric resolution). One may also have to consider the sensor's potential to acquire information at different viewing angles (angular resolution) or polarization channels (polimetric resolution).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aims of the practical session\n",
    "\n",
    "This practical has three aims:\n",
    "1. To understand the differences between the spatial and spectral resolutions of different satellite sensors.\n",
    "2. To plot the spectral signature of different land cover types, and\n",
    "3. Learn how to use band-combinations to highlight different landscape features \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "In this notebook we'll load images from three different sensors and will use them to understand the differences between spatial and spectral resolution in the remote sensing context. \n",
    "\n",
    "First we will:\n",
    "- Load Landsat, Sentinel 2, and MODIS images for the Canberra region.\n",
    "\n",
    "Then we will:\n",
    "- visualize the images of the different sensors side-by-side to understand the concept of spatial resolution;\n",
    "- Compare the spectral resolution (how many 'bands') of different sensors;\n",
    "- Apply various band-combinations to Landsat images to highlight different landscape features.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Assessment:</b> Once you finish the practical and the excercises, remember to submit your notebook through Wattle by Sunday.\n",
    "Challenges are optional and will not be part of the assessment.\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "Import Python packages that are used for the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:23.228159Z",
     "start_time": "2022-07-24T21:00:18.463838Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import geemap as gmap\n",
    "import os\n",
    "import ee\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Google Earth Engine (GEE)\n",
    "\n",
    "Connect to the GEE so we can access GEE datasets and computing assets.\n",
    "You may be required to input your Google account name and password. Please keep those safe and don't share them with anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:28.765377Z",
     "start_time": "2022-07-24T21:00:23.233109Z"
    }
   },
   "outputs": [],
   "source": [
    "m = gmap.Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the spatial resolution of different sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `MODIS` and `Sentinel-2` image collections that intersect the ACT and visualize them in a map\n",
    "\n",
    "First, let's create a polygon around the ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:30.662525Z",
     "start_time": "2022-07-24T21:00:28.769322Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a polygon around the ACT\n",
    "act = ee.Geometry.Polygon([[148.7392751586051,-36.011462319908816],\n",
    "   [149.8598806273551,-36.011462319908816],\n",
    "   [149.8598806273551,-35.1087997777942],\n",
    "   [148.7392751586051,-35.1087997777942],\n",
    "   [148.7392751586051,-36.011462319908816]])\n",
    "\n",
    "# Let's add the polygon to the map\n",
    "Map = gmap.Map(center=[-35.2041, 149.2721], zoom=10)\n",
    "Map.addLayer(act,{},'act')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick note on image composites\n",
    "In the code below, we filter the datasets to a time-range `.filterDate('2019-02', '2019-04')`, this will give us a two-month long time-series of satellite images over that region. We then _reduce_ that time-series (collapse the time-dimension) with the function `.median()`, which will create what Earth Observation scientists call a 'composite image', that is, an image that is representative of all images over a given time. Individual remote sensing images can be affected by noisy data, including clouds, cloud shadows, and haze. To produce cleaner images that can be compared more easily across time, we can create 'summary' images or 'composites' that combine multiple images into one. Median summaries are an extremely useful and very commonly used approach to summarising time-series of satellite images.\n",
    "\n",
    "> Note, to 'clip' an imageCollection to a polygon, we can't rely on the syntax `.filterBounds()`, instead we need to map the `image.clip` function over the time-series. ie. `modis.map(lambda image: image.clip(polygon))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:31.975758Z",
     "start_time": "2022-07-24T21:00:30.668451Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's add the image collections.\n",
    "s2 = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "\n",
    "modis = ee.ImageCollection(\"MODIS/061/MYD09A1\").select([\n",
    "    'sur_refl_b01',\n",
    "    'sur_refl_b02',\n",
    "    'sur_refl_b03',\n",
    "    'sur_refl_b04',\n",
    "    'sur_refl_b05',\n",
    "    'sur_refl_b06',\n",
    "    'sur_refl_b07'])\n",
    "\n",
    "# Filter the image collections by date, and by location, then reduce time dim using median\n",
    "s2 = s2.filterDate('2019-02', '2019-04').map(lambda image: image.clip(act)).median()\n",
    "modis = modis.filterDate('2019-02', '2019-04').map(lambda image: image.clip(act)).median()\n",
    "\n",
    "# Lastly, let's give some visualization paramaters to each collection.\n",
    "s2VisParam = {'bands': [\"B4\",\"B3\",\"B2\"],\n",
    "              'max': 2700,\n",
    "              'min': 0}\n",
    "\n",
    "# Note that the visualization are different for each image collection.\n",
    "modisVisParams = {'bands': [\"sur_refl_b01\",\"sur_refl_b04\",\"sur_refl_b03\"],\n",
    "              'max': 2100,\n",
    "              'min': 0}\n",
    "              \n",
    "Map.addLayer(s2, s2VisParam, 's2')\n",
    "Map.addLayer(modis, modisVisParams, 'modis')\n",
    "Map.addLayerControl()\n",
    "\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "### Exercise 1 - Add a `Landsat 8` image collection to the map.\n",
    "\n",
    "You've done this before, just make sure you filter the image collection with the same dates as the ones above, and reduce the time-series using the `.median()` function\n",
    "\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:31.991714Z",
     "start_time": "2022-07-24T21:00:31.980743Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "### Exercise 2 - Understanding spatial resolution\n",
    "\n",
    "**Answer the following questions:**\n",
    "\n",
    "1) What is the smallest feature you can identify using the MODIS, Landsat, and Sentinel 2 imagery?\n",
    "    \n",
    "2) Which satellite sensor has the highest and lowest spatial resolution.\n",
    "\n",
    "\n",
    "\n",
    "Try identifying the following features / places / landmarks:\n",
    ">- Telstra Tower\n",
    ">- a car\n",
    ">- a football/cricket field\n",
    ">- Canberra Airport\n",
    ">- Lake George,\n",
    ">- a crop field\n",
    ">- a mountain range or a large forest.\n",
    "\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer goes here:\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the spectral resolution of different sensors\n",
    "\n",
    "There are few hyperspectral sensors in orbit.\n",
    "\n",
    "Fortunately, we have access to [Hyperion](https://www.usgs.gov/centers/eros/science/earth-observing-1-eo-1) data. Hyperion was a hyperspectral sensor that was Decommissioned in 2017, but gathered data in many places around the globe.\n",
    "\n",
    "As with the other sensors, we can add these data to our map, and filter by date and location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Caution** Because Hyperion only provides irradiance data, we might have to 1) either perform atmospheric correction, or 2) load TOA Landsat data and uncorrected MODIS so the plots are comparable\n",
    "\n",
    "> Remember, whenever we load Landsat Collection2, we need to rescale the digital numbers to surface-reflectance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale_landsatC2(image):\n",
    "    # Apply the scaling factors to the appropriate bands.\n",
    "    opticalBands = image.select('SR_B.').multiply(0.0000275).add(-0.2)\n",
    "    # Replace the original bands with the scaled ones\n",
    "    return image.addBands(opticalBands, None, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:35.528943Z",
     "start_time": "2022-07-24T21:00:31.995703Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map2 = gmap.Map(center=[-35.2041, 149.2721], zoom=9)\n",
    "\n",
    "# Get the Hyperion image collection and a Landsat image to display\n",
    "hyper = ee.ImageCollection(\"EO1/HYPERION\").map(lambda image: image.clip(act)).median()\n",
    "\n",
    "# load Landsat but only load the optical bands an then rescale\n",
    "clearC2 = ee.Image('LANDSAT/LC08/C02/T1_L2/LC08_090085_20210118') \\\n",
    "        .select(['SR_B1','SR_B2','SR_B3','SR_B4','SR_B5','SR_B6','SR_B7']).clip(act)\n",
    "clearC2 = rescale_landsatC2(clearC2)\n",
    "\n",
    "# Set the visualization parameters for the images we're going to display\n",
    "hyperVisParams = {'bands': [\"B035\",\"B023\",\"B015\"],\n",
    "                 'min':500,\n",
    "                 'max':6000}\n",
    "\n",
    "landsatC2_vis = {'bands': ['SR_B4', 'SR_B3', 'SR_B2'],\n",
    "              'min': 0,\n",
    "              'max': 0.4}\n",
    "\n",
    "# Add the layers to the map\n",
    "Map2.addLayer(modis, modisVisParams, 'MODIS image collection')\n",
    "Map2.addLayer(clearC2, landsatC2_vis,' Landsat image')\n",
    "Map2.addLayer(hyper, hyperVisParams, 'Hyperion hyperspectral image collection')\n",
    "Map2.set_plot_options(add_marker_cluster=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the spectral signatures of different land covers\n",
    "\n",
    "Let's use the plotting tool to  produce simple spectral signature plots for the different sensors (we did this last week, but manually). Click on the map toolbar and select the 'Plotting' icon as shown below. **Pay attention to the image selected for this excercise**.\n",
    "\n",
    "![3.1_fig3.PNG](https://github.com/nicolasyounes/engn3903/raw/main/figures/3.1_fig3.PNG)\n",
    "\n",
    "Now click anywhere on the image and look at the spectral signature of the selected feature. Is it what you would expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:36.626176Z",
     "start_time": "2022-07-24T21:00:35.532937Z"
    }
   },
   "outputs": [],
   "source": [
    "Map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "### Exercise 3 - Understanding the spectral resolution.\n",
    "\n",
    "**Compare and contrast:**\n",
    "\n",
    "1) The spatial *coverage* of the MODIS data, versus the Hyperion data\n",
    "    \n",
    "2) The spectral resolution of the MODIS, Landsat, and Hyperion images.\n",
    "\n",
    "</div>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to, we can export these points and their corresponding band values to a CSV and Shapefile to use them in another software (e.g. QGIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:36.657624Z",
     "start_time": "2022-07-24T21:00:36.632471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the path to the 'Downloads' folder in your computer\n",
    "folder = '/scratch/du53/path-to-a-folder/'\n",
    "Map2.extract_values_to_points(os.path.join(folder, 'spectral_signatures.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the spectral signatures of different land covers programmatically\n",
    "\n",
    "Some points covering different landcover classes have been collected for you. We will use these points to extract the spectral signature of the landcover classes programmatically.\n",
    "\n",
    "The web app : [geojson.io](http://geojson.io/#map=2/0/20) is great for quickly collecting geometries interactively.\n",
    "\n",
    "\n",
    "First we need to load the points into the map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load pre-collected samples:\n",
    "path = \"https://raw.githubusercontent.com/nicolasyounes/engn3903/main/week3/landcover_points.geojson\"\n",
    "points = gmap.geojson_to_ee(path)\n",
    "\n",
    "#print how many classes there are in the TD\n",
    "df = gmap.ee_to_geopandas(points)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now recreate the map with all the satellite images on it, and let's add the points as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T23:26:08.707640Z",
     "start_time": "2022-07-24T23:26:07.271689Z"
    }
   },
   "outputs": [],
   "source": [
    "Map3 = gmap.Map(center=[-35.9659, 149.4965], zoom=9)\n",
    "\n",
    "# Add the layers to the map\n",
    "Map3.addLayer(modis, modisVisParams, 'MODIS image collection')\n",
    "Map3.addLayer(clearC2, landsatC2_vis,' Landsat image')\n",
    "Map3.addLayer(hyper, hyperVisParams, 'Hyperion hyperspectral image collection')\n",
    "\n",
    "#plot the points\n",
    "Map3.addLayer(points, {}, 'training_data')\n",
    "\n",
    "#mapping options\n",
    "Map3.addLayerControl()\n",
    "Map3.set_plot_options(add_marker_cluster=True)\n",
    "Map3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract band values for each pixel in the samples collected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T23:27:10.201131Z",
     "start_time": "2022-07-24T23:27:10.179138Z"
    }
   },
   "outputs": [],
   "source": [
    "pointsLandsat = clearC2.sampleRegions(**\n",
    "                               {'collection': points,\n",
    "                                'scale': 30,\n",
    "                                'geometries': True,\n",
    "                               'tileScale': 8}\n",
    "                               )\n",
    "\n",
    "# Now let's do the same with the MODIS images\n",
    "pointsModis = modis.sampleRegions(**\n",
    "                               {'collection': points,\n",
    "                                'scale': 500,\n",
    "                                'geometries': True,\n",
    "                               'tileScale': 8}\n",
    "                               )\n",
    "# Now let's do the same with the Hyperion images\n",
    "pointsHyperion = hyper.sampleRegions(**\n",
    "                               {'collection': points,\n",
    "                                'scale': 30,\n",
    "                                'geometries': True,\n",
    "                               'tileScale': 8}\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each point has the values for each Landsat band, MODIS and Hyperion band, we can export the points with the band values to a 'dataframe' (a table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T23:27:14.398795Z",
     "start_time": "2022-07-24T23:27:13.691573Z"
    }
   },
   "outputs": [],
   "source": [
    "df_landsat = gmap.ee_to_pandas(pointsLandsat, verbose=True)\n",
    "df_modis = gmap.ee_to_pandas(pointsModis, verbose=True)\n",
    "df_hyperion = gmap.ee_to_pandas(pointsHyperion, verbose=True)\n",
    "\n",
    "# Now we'll sort the 'label' column to make the figure below look a bit better.\n",
    "df_landsat = df_landsat.sort_values(by=['label'])\n",
    "df_modis = df_modis.sort_values(by=['label'])\n",
    "df_hyperion = df_hyperion.sort_values(by=['label'])\n",
    "\n",
    "# and we re-oder the MODIS columns. See https://lpdaac.usgs.gov/products/myd09a1v061/ to understand the order.\n",
    "modisColumnOrder = ['landcover', 'label', 'sur_refl_b03','sur_refl_b04','sur_refl_b01','sur_refl_b02',\n",
    " 'sur_refl_b05','sur_refl_b06','sur_refl_b07']\n",
    "df_modis = df_modis[modisColumnOrder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print the dataframe to see how its organised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the spectral signatures of each sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:43.890082Z",
     "start_time": "2022-07-24T21:00:43.890082Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplot_mosaic(\n",
    "    [['a)', 'b)'], \n",
    "     ['c)', 'c)'],\n",
    "], constrained_layout=True, figsize=(15,7))\n",
    "\n",
    "#do some data wrangling to get the dataframe in a form that plots nicely\n",
    "df_modis.reset_index(drop=True).set_index('label').drop('landcover', axis=1).T.sort_index(axis=0).groupby(level=0, axis=1).mean().plot(ax=axes['a)'])\n",
    "df_landsat.reset_index(drop=True).set_index('label').drop('landcover', axis=1).T.sort_index(axis=0).groupby(level=0, axis=1).mean().plot(ax=axes['b)'])\n",
    "df_hyperion.reset_index(drop=True).set_index('label').drop('landcover', axis=1).T.sort_index(axis=0).groupby(level=0, axis=1).mean().plot(ax=axes['c)'])\n",
    "\n",
    "\n",
    "# Set the lables for the axes    \n",
    "axes['a)'].set_ylabel('MODIS reflectance')\n",
    "axes['b)'].set_ylabel('Landsat reflectance')\n",
    "axes['c)'].set_ylabel('Hyperion radiance')\n",
    "axes['a)'].set_xlabel('MODIS bands')\n",
    "axes['b)'].set_xlabel('Landsat bands')\n",
    "axes['c)'].set_xlabel('Hyperion bands')\n",
    "axes['a)'].set_title('MODIS data')\n",
    "axes['b)'].set_title('Landsat data')\n",
    "axes['c)'].set_title('Hyperion data');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Band Combinations\n",
    "\n",
    "The previous exercise showed you that features in an image look different in different bands. Some bands are better to detect the presence (or absence) of a feature.\n",
    "For example, the Near Infrared (NIR) and Short-Wave Infrared (SWIR) bands are very useful to detect vegetation, and water. We can combine these bands to create 'color composites' (a.k.a false color images). A false color image is used to reveal or enhance features otherwise invisible or poorly visible to a human eye.\n",
    "\n",
    "![false%20color.png](https://github.com/nicolasyounes/engn3903/raw/main/figures/false%20color.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map4 = gmap.Map(center=[-35.9659, 149.4965], zoom=8)\n",
    "\n",
    "# Geth  a Landsat image to display\n",
    "clearC2 = ee.Image('LANDSAT/LC08/C02/T1_L2/LC08_090085_20210118') \\\n",
    "        .select(['SR_B1','SR_B2','SR_B3','SR_B4','SR_B5','SR_B6','SR_B7',])\n",
    "\n",
    "clearC2 = rescale_landsatC2(clearC2)\n",
    "\n",
    "# Select the bands we want to display for the false color composite\n",
    "falseColor = {'bands': ['SR_B5', 'SR_B4', 'SR_B3'], 'min':0, 'max':0.4}\n",
    "trueColor_vis = {'bands': ['SR_B4', 'SR_B3', 'SR_B2'],'min': 0,'max': 0.4}\n",
    "\n",
    "# Add the layers to the map\n",
    "Map4.addLayer(clearC2,  falseColor, \"False Color NIR,R,G\")\n",
    "Map4.addLayer(clearC2, trueColor_vis,'True Colour R,G,B')\n",
    "Map4.addLayerControl()\n",
    "Map4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "### Exercise 3 -  False color images\n",
    "\n",
    "It is your turn to create some false color images.\n",
    "\n",
    "Create false color images using the following bands (add new visualization layers to the map rendered above), and then answer the questions below:\n",
    "\n",
    "- [SWIR1, NIR, Green]\n",
    "- [Green, SWIR, NIR]\n",
    "- [SWIR1, NIR, Blue]\n",
    "- [NIR, SWIR1, Red]\n",
    "\n",
    "\n",
    "**Answer the following questions:**\n",
    "* Which false colour band combinations best show up vegetation? Why?\n",
    "* Which false colour band combinations best show up urban areas? Why?\n",
    "* Which false colour band combinations best shows the shallow, sediment filled water of Lake George? Why?\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T04:03:41.740902Z",
     "start_time": "2022-06-02T04:03:41.724908Z"
    },
    "tags": []
   },
   "source": [
    "**The answers to the questions go here.**\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook you have learned about how different sensors have different spatial and spectral resolutions.  The attributes of specific satellite sensors **will** affect your analysis, so you'll have to understand which sensor is better for which analysis.  Lastly, we also considered how different band combinations can be used to visualise features in the landscape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**Sources:** \n",
    "\n",
    "**License:** The code in this notebook is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/). \n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the ENGN3903 Wattle (**check**) site \n",
    "\n",
    "**Last modified:** August 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
