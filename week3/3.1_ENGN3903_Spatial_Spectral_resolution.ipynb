{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spatial and spectral resolutions.\n",
    "\n",
    "* **Special requirements:** A Google account, access to Google Earth Engine.\n",
    "* **Prerequisites:** You should have completed the `2.1_ENGN3903_Satellite images and bands`, the `2.2 ENGN3903_Images, collections, and filters` notebook.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "> Note: Refer to Lecture 2 of week 2 for the relevant content for this lab\n",
    "\n",
    "Resolution is the ability to discriminate information in an image. The discrimination of information refers not only to the spatial detail (spatial resolution) but also to the number of spectral wavebands, their bandwidths, and spectral cover (spectral resolution), the temporal frequency of observations (temporal resolution) and the signal to noise ratio or its ability to distinguish variations in the energy detected (radiometric resolution). One may also have to consider the sensor's potential to acquire information at different viewing angles (angular resolution) or polarization channels (polimetric resolution).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aims of the practical session\n",
    "\n",
    "This practical has three aims:\n",
    "1. To understand the differences between the spatial and spectral resolutions of different satellite sensors.\n",
    "2. To plot the spectral signature of different land cover types, and\n",
    "3. Learn how to use band-combinations to highlight different landscape features \n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "In this notebook we'll load images from three different sensors and will use them to understand the differences between spatial and spectral resolution in the remote sensing context. \n",
    "\n",
    "First we will:\n",
    "- Load Landsat, Sentinel 2, and MODIS images for the Canberra region.\n",
    "\n",
    "Then we will:\n",
    "- visualize the images of the different sensors side-by-side to understand the concept of spatial resolution;\n",
    "- Compare the spectral resolution of different sensors (how many 'bands' or 'measurements' thye have);\n",
    "- Apply various band-combinations to Landsat images to highlight different landscape features.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Assessment:</b> Once you finish the practical and the excercises, remember to submit your notebook through Wattle by Sunday.\n",
    "Challenges are optional and will not be part of the assessment.\n",
    "</div>\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "\n",
    "Import Python packages that are used for the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:23.228159Z",
     "start_time": "2022-07-24T21:00:18.463838Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %matplotlib inline\n",
    "import os\n",
    "import ee\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geemap as gmap\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to Google Earth Engine (GEE)\n",
    "\n",
    "Connect to the GEE so we can access GEE datasets and computing assets.\n",
    "You may be required to input your Google account name and password. Please keep those safe and don't share them with anyone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:28.765377Z",
     "start_time": "2022-07-24T21:00:23.233109Z"
    }
   },
   "outputs": [],
   "source": [
    "m = gmap.Map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the spatial resolution of different sensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `MODIS` and `Sentinel-2` image collections that intersect the ACT and visualize them in a map\n",
    "\n",
    "First, let's create a polygon around the ACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:30.662525Z",
     "start_time": "2022-07-24T21:00:28.769322Z"
    }
   },
   "outputs": [],
   "source": [
    "# create a polygon around the ACT\n",
    "act = ee.Geometry.Polygon([[148.7392751586051,-36.011462319908816],\n",
    "   [149.8598806273551,-36.011462319908816],\n",
    "   [149.8598806273551,-35.1087997777942],\n",
    "   [148.7392751586051,-35.1087997777942],\n",
    "   [148.7392751586051,-36.011462319908816]])\n",
    "\n",
    "# Let's add the polygon to the map\n",
    "Map = gmap.Map(center=[-35.2041, 149.2721], zoom=10)\n",
    "Map.addLayer(act,{},'act')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A quick note on image composites\n",
    "In the code below, we filter the datasets to a time-range `.filterDate('2019-02', '2019-04')`, this will give us a two-month long time-series of satellite images over that region. We then _reduce_ that time-series (collapse the time-dimension) with the function `.median()`, which will create what Earth Observation scientists call a 'composite image', that is, an image that is representative of all images over a given time. Individual remote sensing images can be affected by noisy data, including clouds, cloud shadows, and haze. To produce cleaner images that can be compared more easily across time, we can create 'summary' images or 'composites' that combine multiple images into one. Median summaries are an extremely useful and very commonly used approach to summarising time-series of satellite images.\n",
    "\n",
    "> Note, to 'clip' an imageCollection to a polygon, we can't rely on the syntax `.filterBounds()` like when we clip just an Image, instead we need to map the `image.clip` function over the time-series. ie. `modis.map(lambda image: image.clip(polygon))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:31.975758Z",
     "start_time": "2022-07-24T21:00:30.668451Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's add the image collections.\n",
    "s2 = ee.ImageCollection(\"COPERNICUS/S2_SR_HARMONIZED\")\n",
    "modis = ee.ImageCollection(\"MODIS/061/MYD09A1\").select([\n",
    "    'sur_refl_b01',\n",
    "    'sur_refl_b02',\n",
    "    'sur_refl_b03',\n",
    "    'sur_refl_b04',\n",
    "    'sur_refl_b05',\n",
    "    'sur_refl_b06',\n",
    "    'sur_refl_b07'])\n",
    "\n",
    "# Filter the image collections by date, and by location, then reduce time dimension using a median\n",
    "s2 = s2.filterDate('2019-02', '2019-04').map(lambda image: image.clip(act)).median()\n",
    "modis = modis.filterDate('2019-02', '2019-04').map(lambda image: image.clip(act)).median()\n",
    "\n",
    "# Lastly, let's give some visualization paramaters to each collection.\n",
    "s2VisParam = {'bands': [\"B4\",\"B3\",\"B2\"],\n",
    "              'max': 2700, #this data hasn't been rescaled\n",
    "              'min': 0}\n",
    "\n",
    "# Note that the visualization are different for each image collection.\n",
    "modisVisParams = {'bands': [\"sur_refl_b01\",\"sur_refl_b04\",\"sur_refl_b03\"],\n",
    "              'max': 2100,\n",
    "              'min': 0}\n",
    "\n",
    "#add images to the map\n",
    "Map.addLayer(s2, s2VisParam, 's2')\n",
    "Map.addLayer(modis, modisVisParams, 'modis')\n",
    "Map.addLayerControl()\n",
    "Map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "### Exercise 1 - Add a `Landsat 8` image collection to the map.\n",
    "\n",
    "You've done this in earlier labs, just make sure you filter the image collection with the same dates as the ones above, and reduce the time-series using the `.median()` function.  Remember to rescale the dataset as well, and call your rescaling function `rescale_landsatC2()`. For this one example, you can ignore cloud masking.\n",
    "\n",
    "</div>  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:31.991714Z",
     "start_time": "2022-07-24T21:00:31.980743Z"
    }
   },
   "outputs": [],
   "source": [
    "# Your code goes here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "### Exercise 2 - Understanding spatial resolution\n",
    "\n",
    "**Answer the following questions:**\n",
    "\n",
    "1) What is the smallest feature you can identify using the MODIS, Landsat, and Sentinel 2 imagery?\n",
    "    \n",
    "2) Which satellite sensor has the highest and lowest spatial resolution.\n",
    "\n",
    "\n",
    "\n",
    "To help with your ansers, try identifying the following features / places / landmarks:\n",
    ">- Telstra Tower\n",
    ">- a car\n",
    ">- a football/cricket field\n",
    ">- Canberra Airport\n",
    ">- Lake George,\n",
    ">- a crop field\n",
    ">- a mountain range or a large forest.\n",
    "\n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answer goes here:\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the spectral resolution of different sensors\n",
    "\n",
    "There are only a few hyperspectral sensors in orbit.  Fortunately, we have access to [Hyperion](https://www.usgs.gov/centers/eros/science/earth-observing-1-eo-1) data. Hyperion was a hyperspectral sensor that was Decommissioned in 2017, but gathered data in many places around the globe.\n",
    "\n",
    "As with the other sensors, we can add these data to our map, and filter by date and location.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Caution** Because Hyperion only provides irradiance data, we might have to 1) either perform atmospheric correction, or 2) load TOA Landsat data and uncorrected MODIS so the plots are comparable. We aren't doing this here, but its something to keep in mind when considering the differences between sensors.\n",
    "\n",
    "> Remember, whenever we load Landsat Collection2, we need to rescale the digital numbers to surface-reflectance. You should have defined a function for this in Exercise 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:35.528943Z",
     "start_time": "2022-07-24T21:00:31.995703Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "Map2 = gmap.Map(center=[-35.2041, 149.2721], zoom=9)\n",
    "\n",
    "# Get the Hyperion image collection and clip to the canberra region\n",
    "hyper = ee.ImageCollection(\"EO1/HYPERION\").map(lambda image: image.clip(act)).median()\n",
    "\n",
    "# load Landsat but only load the optical bands an then rescale\n",
    "clearC2 = ee.Image('LANDSAT/LC08/C02/T1_L2/LC08_090085_20210118') \\\n",
    "        .select(['SR_B1','SR_B2','SR_B3','SR_B4','SR_B5','SR_B6','SR_B7']).clip(act)\n",
    "\n",
    "clearC2 = rescale_landsatC2(clearC2)\n",
    "\n",
    "# Set the visualization parameters for the images we're going to display\n",
    "hyperVisParams = {'bands': [\"B035\",\"B023\",\"B015\"],\n",
    "                 'min':500,\n",
    "                 'max':6000}\n",
    "\n",
    "landsatC2_vis = {'bands': ['SR_B4', 'SR_B3', 'SR_B2'],\n",
    "              'min': 0, # this data has been rescaled so is 0-1\n",
    "              'max': 0.4}\n",
    "\n",
    "# Add the layers to the map\n",
    "Map2.addLayer(modis, modisVisParams, 'MODIS image collection')\n",
    "Map2.addLayer(clearC2, landsatC2_vis,' Landsat image')\n",
    "Map2.addLayer(hyper, hyperVisParams, 'Hyperion hyperspectral image collection')\n",
    "Map2.set_plot_options(add_marker_cluster=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the spectral signatures of different land covers\n",
    "\n",
    "Let's use the plotting tool to  produce simple spectral signature plots for the different sensors (we did this last week, but we manually enetered the numbers). Click on the map toolbar and select the 'Plotting' icon as shown below. **Pay attention to the images selected in the toolbar for this exercise**.\n",
    "\n",
    "![3.1_fig3.PNG](https://github.com/nicolasyounes/engn3903/raw/main/figures/3.1_fig3.PNG)\n",
    "\n",
    "Now click anywhere on the image and look at the spectral signature of the selected feature. Is it what you would expect?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:36.626176Z",
     "start_time": "2022-07-24T21:00:35.532937Z"
    }
   },
   "outputs": [],
   "source": [
    "Map2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "    \n",
    "### Exercise 3 - Understanding the spectral resolution.\n",
    "\n",
    "**Compare and contrast:**\n",
    "\n",
    "1) The spatial *coverage* of the MODIS data, versus the Hyperion data\n",
    "    \n",
    "2) The spectral resolution of the MODIS, Landsat, and Hyperion images.\n",
    "\n",
    "</div>    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your answers go here\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we wanted to, we can export these points and their corresponding band values to a CSV and Shapefile to use them in another software (e.g. QGIS/ArcGIS). \n",
    "\n",
    "**Below, change the path to the your folder on the NCI, and your plots in the map above will be exported as .csv files. The points your select on the map will also be exported as shapefile (we'll discuss vector file formats more soon).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:36.657624Z",
     "start_time": "2022-07-24T21:00:36.632471Z"
    }
   },
   "outputs": [],
   "source": [
    "# Change the path to the your folder on the NCI, \n",
    "folder = '/scratch/du53/path-to-a-folder/'\n",
    "Map2.extract_values_to_points(os.path.join(folder, 'spectral_signatures.shp'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the spectral signatures of different land covers programmatically\n",
    "\n",
    "Some points covering different landcover classes have been collected for you. We will use these points to extract the spectral signature of the landcover classes programmatically.\n",
    "\n",
    "The web app : [geojson.io](http://geojson.io/#map=2/0/20) is great for quickly collecting geometries interactively.\n",
    "\n",
    "\n",
    "**First we need to load the points into the map**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### load pre-collected samples:\n",
    "path = \"https://raw.githubusercontent.com/nicolasyounes/engn3903/main/figures/landcover_points.geojson\"\n",
    "points = gmap.geojson_to_ee(path)\n",
    "\n",
    "# Convert to dataframe so we can see the values\n",
    "df = gmap.ee_to_df(points, remove_geom=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now recreate the map with all the satellite images on it, and let's add the points as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T23:26:08.707640Z",
     "start_time": "2022-07-24T23:26:07.271689Z"
    }
   },
   "outputs": [],
   "source": [
    "Map3 = gmap.Map(center=[-35.9659, 149.4965], zoom=9)\n",
    "\n",
    "# Add the layers to the map\n",
    "Map3.addLayer(modis, modisVisParams, 'MODIS image collection')\n",
    "Map3.addLayer(clearC2, landsatC2_vis,' Landsat image')\n",
    "Map3.addLayer(hyper, hyperVisParams, 'Hyperion hyperspectral image collection')\n",
    "\n",
    "#plot the points\n",
    "Map3.addLayer(points, {}, 'points to extract')\n",
    "\n",
    "#mapping options\n",
    "Map3.addLayerControl()\n",
    "Map3.set_plot_options(add_marker_cluster=True)\n",
    "Map3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract band values for each pixel in the samples collected\n",
    "\n",
    "Below, we use the function `'sampleRegions'` to extract the pixel values at the location identified by the `points` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T23:27:10.201131Z",
     "start_time": "2022-07-24T23:27:10.179138Z"
    }
   },
   "outputs": [],
   "source": [
    "pointsLandsat = clearC2.sampleRegions(**\n",
    "                               {'collection': points,\n",
    "                                'scale': 30,\n",
    "                                'geometries': True,\n",
    "                               'tileScale': 8}\n",
    "                               )\n",
    "\n",
    "# Now let's do the same with the MODIS images\n",
    "pointsModis = modis.sampleRegions(**\n",
    "                               {'collection': points,\n",
    "                                'scale': 500,\n",
    "                                'geometries': True,\n",
    "                               'tileScale': 8}\n",
    "                               )\n",
    "# Now let's do the same with the Hyperion images\n",
    "pointsHyperion = hyper.sampleRegions(**\n",
    "                               {'collection': points,\n",
    "                                'scale': 30,\n",
    "                                'geometries': True,\n",
    "                               'tileScale': 8}\n",
    "                               )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each point has the values for each Landsat band, MODIS and Hyperion band, we can convert the points with the band values to a 'dataframe' (a table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T23:27:14.398795Z",
     "start_time": "2022-07-24T23:27:13.691573Z"
    }
   },
   "outputs": [],
   "source": [
    "df_landsat = gmap.ee_to_df(pointsLandsat, remove_geom=True)\n",
    "df_modis = gmap.ee_to_df(pointsModis, remove_geom=True)\n",
    "df_hyperion = gmap.ee_to_df(pointsHyperion, remove_geom=True)\n",
    "\n",
    "# Now we'll sort the 'label' column to make the figure below look a bit better.\n",
    "df_landsat = df_landsat.sort_values(by=['label'])\n",
    "df_modis = df_modis.sort_values(by=['label'])\n",
    "df_hyperion = df_hyperion.sort_values(by=['label'])\n",
    "\n",
    "# and we re-oder the MODIS columns. See https://lpdaac.usgs.gov/products/myd09a1v061/ to understand the order.\n",
    "modisColumnOrder = ['landcover', 'label', 'sur_refl_b03','sur_refl_b04','sur_refl_b01','sur_refl_b02',\n",
    "                                          'sur_refl_b05','sur_refl_b06','sur_refl_b07']\n",
    "df_modis = df_modis[modisColumnOrder]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can print one of the dataframe to see how its organised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_modis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the spectral signatures of each sensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-24T21:00:43.890082Z",
     "start_time": "2022-07-24T21:00:43.890082Z"
    }
   },
   "outputs": [],
   "source": [
    "with plt.style.context('ggplot'): #use ggplot styles (similar to R)\n",
    "    #set the plot mosaic grid so its neat.\n",
    "    fig, axes = plt.subplot_mosaic(\n",
    "        [['a)', 'b)'], \n",
    "         ['c)', 'c)'],\n",
    "    ], constrained_layout=True, figsize=(15,7))\n",
    "    \n",
    "    #do some data wrangling to get the dataframe in a form that plots nicely\n",
    "    df_modis.reset_index(drop=True).set_index('label').drop('landcover', axis=1).T.sort_index(axis=0).groupby(level=0, axis=1).mean().plot(ax=axes['a)'])\n",
    "    df_landsat.reset_index(drop=True).set_index('label').drop('landcover', axis=1).T.sort_index(axis=0).groupby(level=0, axis=1).mean().plot(ax=axes['b)'])\n",
    "    df_hyperion.reset_index(drop=True).set_index('label').drop('landcover', axis=1).T.sort_index(axis=0).groupby(level=0, axis=1).mean().plot(ax=axes['c)'])\n",
    "    \n",
    "    # Set the lables for the axes    \n",
    "    axes['a)'].set_ylabel('MODIS reflectance')\n",
    "    axes['b)'].set_ylabel('Landsat reflectance')\n",
    "    axes['c)'].set_ylabel('Hyperion radiance')\n",
    "    axes['a)'].set_xlabel('MODIS bands')\n",
    "    axes['b)'].set_xlabel('Landsat bands')\n",
    "    axes['c)'].set_xlabel('Hyperion bands')\n",
    "    axes['a)'].set_title('MODIS data')\n",
    "    axes['b)'].set_title('Landsat data')\n",
    "    axes['c)'].set_title('Hyperion data');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Band Combinations\n",
    "\n",
    "The previous exercise showed you that features in an image look different in different bands. Some bands are better to detect the presence (or absence) of a feature.\n",
    "For example, the Near Infrared (NIR) and Short-Wave Infrared (SWIR) bands are very useful to detect vegetation, and water. We can combine these bands to create 'color composites' (a.k.a false color images). A false color image is used to reveal or enhance features otherwise invisible or poorly visible to a human eye.\n",
    "\n",
    "![false%20color.png](https://github.com/nicolasyounes/engn3903/raw/main/figures/false%20color.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Map4 = gmap.Map(center=[-35.9659, 149.4965], zoom=8)\n",
    "\n",
    "# Get  a Landsat image to display\n",
    "clearC2 = ee.Image('LANDSAT/LC08/C02/T1_L2/LC08_090085_20210118') \\\n",
    "        .select(['SR_B1','SR_B2','SR_B3','SR_B4','SR_B5','SR_B6','SR_B7',])\n",
    "\n",
    "#rescale the image\n",
    "clearC2 = rescale_landsatC2(clearC2)\n",
    "\n",
    "# Select the bands we want to display for the false color composite\n",
    "falseColor_vis = {'bands': ['SR_B5', 'SR_B4', 'SR_B3'], 'min':0, 'max':0.4}\n",
    "trueColor_vis = {'bands': ['SR_B4', 'SR_B3', 'SR_B2'],'min': 0,'max': 0.4}\n",
    "\n",
    "\n",
    "# Add the layers to the map\n",
    "Map4.addLayer(clearC2,  falseColor_vis, \"False Color NIR,R,G\")\n",
    "Map4.addLayer(clearC2, trueColor_vis,'True Colour R,G,B')\n",
    "Map4.addLayerControl()\n",
    "Map4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "\n",
    "### Exercise 3 -  False colour images\n",
    "\n",
    "It is your turn to create some different false colour images.\n",
    "\n",
    "Using the Landsat 8 band designations here to help you: https://www.usgs.gov/landsat-missions/landsat-8,\n",
    "\n",
    "**Answer the following questions:**\n",
    "1. How does dense vegetation appear in the false colour band combination: [NIR, SWIR1, Red]? Why?\n",
    "2. How does bare soil appear in the false colour band combination: [SWIR1, NIR, Red]? Why? \n",
    "3. How does shallow, sediment filled water appear in the false colour band combination: [SWIR1, NIR, Green]? Why? Try comparing Lake George (or a farm dam) with Lake Burley Griffin.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-02T04:03:41.740902Z",
     "start_time": "2022-06-02T04:03:41.724908Z"
    },
    "tags": []
   },
   "source": [
    "**The answers to the questions go here.**\n",
    "\n",
    "\n",
    "."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook you have learned about how different sensors have different spatial and spectral resolutions.  The attributes of specific satellite sensors **will** affect your analysis, so you'll have to understand which sensor is better for which analysis.  Lastly, we also considered how different band combinations can be used to visualise features in the landscape. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**Sources:** \n",
    "\n",
    "**License:** The code in this notebook is licensed under a [Creative Commons Attribution 4.0 International License](https://creativecommons.org/licenses/by/4.0/). \n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the ENGN3903 Wattle (**check**) site \n",
    "\n",
    "**Last modified:** August 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "213px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
